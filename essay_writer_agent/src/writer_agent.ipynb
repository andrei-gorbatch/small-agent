{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.messages import (\n",
    "    AnyMessage,\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage,\n",
    "    ChatMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "from tavily import TavilyClient\n",
    "import os\n",
    "import textwrap\n",
    "from IPython.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set-up the model and the memory\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classes\n",
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int\n",
    "\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompts for the different nodes\n",
    "\n",
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\"\n",
    "\n",
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\"\n",
    "\n",
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\"\n",
    "\n",
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n",
    "\n",
    "\n",
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the nodes\n",
    "\n",
    "\n",
    "def plan_node(state: AgentState):\n",
    "    messages = [SystemMessage(content=PLAN_PROMPT), HumanMessage(content=state[\"task\"])]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}\n",
    "\n",
    "\n",
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke(\n",
    "        [\n",
    "            SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "            HumanMessage(content=state[\"task\"]),\n",
    "        ]\n",
    "    )\n",
    "    content = state.get(\"content\", [])\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response[\"results\"]:\n",
    "            content.append(r[\"content\"])\n",
    "    return {\"content\": content}\n",
    "\n",
    "\n",
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state[\"content\"] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\"\n",
    "    )\n",
    "    messages = [\n",
    "        SystemMessage(content=WRITER_PROMPT.format(content=content)),\n",
    "        user_message,\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content,\n",
    "        \"revision_number\": state.get(\"revision_number\", 0) + 1,\n",
    "    }\n",
    "\n",
    "\n",
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT),\n",
    "        HumanMessage(content=state[\"draft\"]),\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}\n",
    "\n",
    "\n",
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke(\n",
    "        [\n",
    "            SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "            HumanMessage(content=state[\"critique\"]),\n",
    "        ]\n",
    "    )\n",
    "    content = state[\"content\"] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response[\"results\"]:\n",
    "            content.append(r[\"content\"])\n",
    "    return {\"content\": content}\n",
    "\n",
    "\n",
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)\n",
    "\n",
    "builder.set_entry_point(\"planner\")\n",
    "\n",
    "builder.add_conditional_edges(\n",
    "    \"generate\", should_continue, {END: END, \"reflect\": \"reflect\"}\n",
    ")\n",
    "\n",
    "\n",
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")\n",
    "\n",
    "\n",
    "# Visualize the graph\n",
    "# Image(graph.get_graph().draw_png())\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the stream\n",
    "task = \"Write an essay on the importance of recycling.\"\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream(\n",
    "    {\n",
    "        \"task\": task,\n",
    "        \"max_revisions\": 2,\n",
    "        \"revision_number\": 0,\n",
    "    },\n",
    "    thread,\n",
    "):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(s.get('generate').get('draft'))\n",
    "paragraphs = s.get(\"generate\").get(\"draft\").split(\"\\n\\n\")\n",
    "\n",
    "for p in paragraphs:\n",
    "    print(textwrap.fill(p, 160))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-QHAvPeIl-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
